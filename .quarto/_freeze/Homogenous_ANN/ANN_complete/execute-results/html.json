{
  "hash": "a72d11bd16522a061e89c03be5302485",
  "result": {
    "markdown": "---\ntitle: \"ANN Hypothesis Testing: homogeneous case\"\nauthor: \"ES214\"\noutput:\n  html_document:\n    toc: yes\n    toc_float: \n      collapsed: false\n  word_document: default\n---\n\n\n\n\n------------------------------------------------------------------------\n\n<p style = \"background-color:#FAEBD7; border-radius: 5px;  padding: 3px\">\n\nData for this tutorial can be downloaded [from here](./walmarts.zip). Don't forget to unzip the files to a dedicated folder on your computer.\n\n<p>\n\n> Don't forget to set the R session to the project folder via *Session \\>\\> Set Working Directory \\>\\> Choose Directory*.\n\n## Load and prep the dataset\n\nIn the following chunk of code, we will load the shapefiles into R, then we will convert the spatial objects into formats that are readable by the `spatstat` functions. We will also convert the mapping units from meters to kilometers using the `rescale` function. This last step will generate distance values of kilometers instead of meters when we compute the average nearest neighbor value. Much like ArcGIS, R will adopt the layer's coordinate system's map units when expressing distance or area values, so by changing the layer's default map units, we end up with output distance values that are no more than 3 or 4 digits long and that have short, or no, fractional components.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(sf)\nlibrary(spatstat)\n\n# Read state polygon data\ns  <- st_read(\"MA.shp\")\nw  <- as.owin(s)\nw.km <- rescale(w, 1000)  # rescale map units to km\n\n# Read Walmart point data\ns  <- st_read(\"Walmarts.shp\")\np  <- as.ppp(s)\nmarks(p) <- NULL  # Remove attribute table (simplifies plot operations)\np.km <- rescale(p, 1000) # Rescale map units to km\nWindow(p.km) <- w.km      \n```\n:::\n\n\n## Average nearest neighbor analysis\n\nFirst, we'll compute the observed Walmart ANN statistic.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nann.p <- mean(nndist(p.km, k=1))\nann.p\n```\n:::\n\n\nThe observed average nearest neighbor is 13.29 km.\n\n### Is our observed ANN value consistent with a random process?\n\nIn this hypothesis test, we are hypothesizing that the process that generated the observed distribution of Walmart stores was completely random. This is our **null hypothesis**. We'll therefore compare our observed ANN value to the *range* of ANN values we could expect to get *if* the Walmart stores were randomly distributed. This will involve randomly shuffling the Walmart store locations, then computing the average distance between the randomly distributed stores. This process is then repeated many times such that a distribution of ANN values under the assumption of complete randomness (the null hypothesis) is generated.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn     <- 1999       # Number of times to run the simulation\nann.r <- vector()   # Create an empty object to be used to store the simulated  ANN values\n\nfor (i in 1:n){\n  rand.p   <- rpoint(n = p.km$n, win = w.km)  # Generate random point locations\n  ann.r[i] <- mean(nndist(rand.p, k = 1))     # Compute and store the simulated ANN value\n}\n```\n:::\n\n\nIn the above loop, the function `rpoint` is passed two parameters: `n = p.km$n` and `win = w.km`. The first tells the function how many points to randomly place (i.e. the same number of points as that in the Walmart points layer which we can extract by typing `p.km$n`). The second tells the function to confine the randomly generated points to the extent defined by `w.km` (the `MA` polygon).\n\nNote that after running the last simulation, you can view its set of randomly generated points via:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(rand.p, pch = 16, main = NULL)\n```\n\n::: {.cell-output-display}\n![](ANN_complete_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nGiven that this is a random process, your output will look different--as expected.\n\nNext, let's plot the histogram of the simulated ANN values then add a blue line showing where our observed ANN value lies relative to the distribution of simulated ANN values under the null. (Your histogram may look different given the random nature of the simulation).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(ann.r, breaks = 40, col = \"bisque\", xlim = range(ann.p, ann.r), main = NULL)\nabline(v = ann.p, col = \"blue\", lw = 2)  # lw = 2 increases the line width\n```\n\n::: {.cell-output-display}\n![](ANN_complete_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nThe test suggests that our observed ANN value may not be that different from the 1999 ANN values we simulated under the assumption that the stores are randomly distributed. Our observed values is a tad bit to the right of the center of the distribution suggesting that our observed ANN value might be on the dispersed side of the range of values (a larger than expected ANN value suggests a more dispersed set of points, and a smaller than expected ANN value suggests a more clustered set of points).\n\n### Extracting a p-value from the simulation\n\nWe first find the end of the distribution that is closest to the observed ANN value. We then find the number of simulated ANN values more extreme than our observed ANN value. Finally, we divide that count by the total number of simulations. Note that this is a so-called *one-sided* P-value. See [lecture notes](https://mgimond.github.io/Spatial/point-pattern-analysis-in-r.html#computing-a-pseudo-p-value) for more information.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN.greater <- sum(ann.r > ann.p)\np <- min(N.greater + 1, n + 1 - N.greater) / (n + 1)\np\n```\n:::\n\n\nThe p-value suggests that we would be 31% wrong in rejecting the null hypothesis that a random process *could* have generated a pattern that is *more dispersed* than our observed pattern.\n\n::: {style=\"background:#FFE4C4;\"}\nNOTES:\n\n-   If you are familiar with the concepts of a one-sided and two-sided test, you could double the p-value and state that *\"... there is a 62% chance of being wrong in rejecting the null hypothesis that a random process could have generated a point pattern similar to our observed pattern\"*. Note the lack of reference to **greater than** or **less than**.\n\n-   Just because our hypothesis test suggests that our observed ANN value is consistent with a random process does not imply that a random process was **the** process behind the distribution of Walmart stores (in fact, it's quite doubtful that Walmart executives assign store location at random). All that a hypothesis test can do is state whether a hypothesized process could be one of **many** other processes that generated the pattern observed in our dataset.\n:::\n\n<hr style=\"height: 3px; background-color: #a7a7a7; border: none;\">\n\n+-------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------+\n| [Back to ES214 R scripts](../README.html) | [![Creative Commons License](https://i.creativecommons.org/l/by-nc/4.0/88x31.png){alt=\"Creative Commons License\"}](http://creativecommons.org/licenses/by-nc/4.0/) | \\_Manny Gimond, 2022\\_ |\n+-------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------+\n",
    "supporting": [
      "ANN_complete_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}