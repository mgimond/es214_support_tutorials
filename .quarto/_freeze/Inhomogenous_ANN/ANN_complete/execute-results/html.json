{
  "hash": "73327f88b38efa33f79dc02b0ddb1bfc",
  "result": {
    "markdown": "---\ntitle: \"ANN Hypothesis Testing: inhomogeneous case\"\nauthor: \"Manny Gimond\"\n---\n\n\n\n\n\n------------------------------------------------------------------------\n\n[Data for this tutorial can be downloaded [from here](./data.zip). Don't forget to unzip the files to a dedicated folder on your computer.]{.block1}\n \n\n> Don't forget to set the R session to the project folder via *Session \\>\\> Set Working Directory \\>\\> Choose Directory*.\n\n-------\n\n## Load and prep the dataset\n\nIn the following chunk of code, we will load the shapefiles into R, then we will convert the spatial objects into formats that are readable by the `spatstat` functions. We will also convert the mapping units from meters to kilometers using the `rescale` function.\n\nAs was noted in our PPM analysis of the population data, given its strongly skewed distribution we found it best to express it on a log scale as opposed to a linear scale. We'll therefore adopt this log scale in this analysis too.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(sf)\nlibrary(maptools)\nlibrary(spatstat)\nlibrary(raster)\n\n# Read state polygon data\ns  <- st_read(\"MA.shp\")\nw  <- as.owin(s)\nw.km <- rescale(w, 1000)\n\n# Read Walmart point data\ns  <- st_read(\"Walmarts.shp\")\np  <- as.ppp(s)\nmarks(p) <- NULL\np.km <- rescale(p, 1000)\nWindow(p.km) <- w.km     \n\n# Read population raster\nimg     <- raster(\"./pop_sqmile.img\") # Creates a raster object\npop     <- as.im(img)  # Convert r object to an im object\npop.km  <- rescale(pop, 1000)\npop.km.log <- log(pop.km)  # Log transform population data\n```\n:::\n\n\n## Average nearest neighbor analysis\n\nFirst, we'll compute the observed Walmart ANN statistic.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nann.p <- mean(nndist(p.km, k=1))\nann.p\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 13.29478\n```\n:::\n:::\n\n\nThe observed average nearest neighbor is 13.29 km.\n\n### Is our observed ANN value consistent with a random process assuming a homogeneous effect?\n\nIn this hypothesis test, we are hypothesizing that the process that generated the observed distribution of Walmart stores was completely random. This is our null hypothesis. We'll therefore compare our observed ANN value to the range of ANN values we could expect to get *if* the Walmart stores were randomly distributed. This will involve randomly shuffling the Walmart store locations, then computing the average distance between the randomly distributed stores. This process is then repeated many times such that a distribution of ANN values under the null is generated.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn     <- 999       # Number of times to run the simulation\nann.hom <- vector() # Create an empty object to be used to store simulated values\n\nfor (i in 1:n){\n  rand.p   <- rpoint(n = p.km$n, win = w.km)  # Generate random point locations\n  ann.hom[i] <- mean(nndist(rand.p, k = 1)) # Computed simulated ANN value\n}\n```\n:::\n\n\nIn the above loop, the function `rpoint` is passed two parameters: `n = p.km$n` and `win = w.km`. The first tells the function how many points to randomly place (i.e. the same number of points as that in the Walmart points layer which we can extract by typing `p.km$n`). The second tells the function to confine the randomly generated points to the extent defined by `w.km` (the MA polygon).\n\nNote that after running the last simulation, you can view its set of randomly generated points via:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(rand.p, pch = 16, main = NULL)\n```\n\n::: {.cell-output-display}\n![](ANN_complete_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nNext, let's plot the histogram of the simulated ANN values then add a blue line showing where our observed ANN value lies relative to the distribution of simulated ANN values under the null.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(ann.hom, breaks = 40, col = \"bisque\", xlim = range(ann.p, ann.hom), main = NULL)\nabline(v = ann.p, col = \"blue\", lw = 2)  # lw = 2 increases the line width\n```\n\n::: {.cell-output-display}\n![](ANN_complete_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nThe test suggests that our observed ANN value may not be that different from an ANN value we could expect to measure had the stores been randomly distributed.\n\n### Extracting a p-value from the simulation\n\nWe first find the end of the distribution that is closest to the observed ANN value. We then find the number of simulated ANN values more extreme than our observed ANN value. Finally, we divide that count by the total number of simulations. Note that this is a so-called *one-sided* P-value. See [lecture notes](https://mgimond.github.io/Spatial/point-pattern-analysis-in-r.html#computing-a-pseudo-p-value) for more information.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN.greater <- sum(ann.hom > ann.p)\np <- min(N.greater + 1, n + 1 - N.greater) / (n + 1)\np\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.315\n```\n:::\n:::\n\n\nThe p-value suggests that we would be 32% wrong in rejecting the null hypothesis that a random process could have generated a pattern that is more dispersed than our observed pattern.\n\n> NOTE: if you are familiar with the concepts of a one-sided and two-sided test, you could double the p-value and state that *\"... there is a 64% chance of being wrong in rejecting the null hypothesis that a random process could have generated a point pattern similar to our observed pattern\"*. Note the lack of reference to **greater than** or **less than**.\n\n### Is our observed ANN value consistent with a random process when controlled for population distribution (inhomogeneous process)?\n\nThe problem with our ANN analysis so far is that we did not account for [1^st^ order effects](https://mgimond.github.io/Spatial/chp11-0.html#first-and-second-order-effects) of the underlying process such as population distribution (a possible covariate). In other words, is the distance observed between Walmart stores a reflection of the attractive/repulsive forces at play when positioning the stores within the state of Massachusetts or is their proximity to one another dictated by some underlying process such as population density distribution?\n\nIf we are to assume that population distribution will influence the distribution of Walmart stores, we need to rerun the ANN analysis while **controlling** for population distribution influence. We do this by instructing the `rpoint()` function to increase point placement probability at locations with high covariate values (i.e. a high population density area is more likely to receive a random point than a low density area).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn     <- 999\nann.het <- vector()\nfor (i in 1:n){\n  rand.p   <- rpoint(n = p.km$n, f = pop.km.log, win = w.km) \n  ann.het[i] <- mean(nndist(rand.p, k = 1))\n}\n```\n:::\n\n\nThe above loop is almost identical to that of the homogeneous case except with the addition of the `f = pop.km.log` argument which defines the intensity of the underlying process (`pop.km.log` represents the population density raster). The `rpoint` function rescales the raster values to a range of `[0,1]` where `1` designates maximum probability of a pixel receiving a point and `0` minimum (or no) probability of a pixel receiving a point. Note that this is still a random process in that each time the `rpoint` function is run, we'll have a different point pattern. However, on average, more points will be located where the `pop.km.log` pixels have the highest values.\n\nNote that the `f =` parameter will supersede that of the `win =` parameter. In other words, if `pop.km.log` covers a different extent than `w.km`, the `rpoint()` function will generate random points within the `pop.km.log` extent instead of the `w.km` extent.\n\nThe following map shows an example of how the Walmart store distribution *could* look like *if* dictated by population alone.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(rand.p, pch = 16, main = NULL)\n```\n\n::: {.cell-output-display}\n![](ANN_complete_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nNow let's plot the histogram of simulated ANN values:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(ann.het, breaks = 40, col = \"bisque\", xlim = range(ann.p, ann.het), main = NULL)\nabline(v = ann.p, col = \"blue\", lw = 2)\n```\n\n::: {.cell-output-display}\n![](ANN_complete_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nThe histogram is displaying the range of expected ANN values when the placement of Walmart points are dictated by the population distribution.\n\nOur observed ANN value lies to the right of the distribution center suggesting that our observed Walmart may be more *dispersed* than expected under the current hypothesis. This makes sense since you would expect there to be a minimum distance between stores to avoid overlapping markets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN.greater <- sum(ann.het > ann.p)\np <- min(N.greater + 1, n + 1 - N.greater) / (n +1)\np\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.141\n```\n:::\n:::\n\n\n## Final note\n\nWhile the wording in the last paragraph may imply that it's the *observed* ANN value that has shifted along the x-axis relative to the hypothesized distribution, it's really the distribution that gets shifted along the x-axis. The following plot overlays the expected ANN distribution given a homogeneous 1^st^ order process in red and the expected ANN distribution given the inhomogeneous 1^st^ order process in green. The observed ANN value of 13.3 km is constant under both analyses.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](ANN_complete_files/figure-html/unnamed-chunk-11-1.png){width=576}\n:::\n:::\n\n\n## Addendum\n\nIt's good practice to indicate, in your analysis results, if you use a transformed version of the covariate since this can impact the outcome of the analysis. In the following example, the original linear version of the population raster is used.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nann.r <- vector()\nfor (i in 1:n){\n  rand.p   <- rpoint(n = p.km$n, f = pop.km, win = w.km) \n  ann.r[i] <- mean(nndist(rand.p, k = 1))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(ann.r, breaks = 40, col = \"bisque\", xlim = range(ann.p, ann.r), main = NULL)\nabline(v = ann.p, col = \"blue\", lw = 2)\n```\n\n::: {.cell-output-display}\n![](ANN_complete_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nN.greater <- sum(ann.r > ann.p)\np <- min(N.greater + 1, n + 1 - N.greater) / (n + 1)\np\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.002\n```\n:::\n:::\n\n\nThe outcome of this analysis is quite different from the one using the raw population density values. **Both outcomes are perfectly valid**, but they address slightly different questions: \"When controlling for the population density distribution, are Walmart stores randomly distributed?\" vs. \"When controlling for the population density distribution **as measured on a log scale**, are Walmart stores randomly distributed?\"\n\n<hr style=\"height: 3px; background-color: #a7a7a7; border: none;\">\n\n+-------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------+\n| [Back to ES214 R scripts](../README.html) | [![Creative Commons License](https://i.creativecommons.org/l/by-nc/4.0/88x31.png){alt=\"Creative Commons License\"}](http://creativecommons.org/licenses/by-nc/4.0/) | \\_Manny Gimond, 2022\\_ |\n+-------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------+\n",
    "supporting": [
      "ANN_complete_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}